{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEPS PER EPOCH:  1114\n",
      "VALIDATION STEPS:  300\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mask_rcnn\n",
    "import mask_rcnn_utils\n",
    "import eye_segmentation\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import keras.layers as KL\n",
    "import keras.engine as KE\n",
    "import keras.models as KM\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmentation dataset\n",
    "DATASET_DIR = '/home/jjonathanmak/cs271proj/Semantic_Segmentation_Dataset' # replace with your path\n",
    "TRAIN_IMAGE_DIR = DATASET_DIR + '/train/images'\n",
    "TRAIN_LABELS_DIR = DATASET_DIR + '/train/labels'\n",
    "VAL_IMAGE_DIR = DATASET_DIR + '/validation/images'\n",
    "VAL_LABELS_DIR = DATASET_DIR + '/validation/labels'\n",
    "TEST_IMAGE_DIR = DATASET_DIR + '/test/images'\n",
    "\n",
    "image_ids = next(os.walk(TEST_IMAGE_DIR))[2]\n",
    "for image_id in image_ids:\n",
    "    print(image_id[:image_id.index('.')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (len(os.listdir(TRAIN_IMAGE_DIR)) == len(os.listdir(TRAIN_LABELS_DIR))) # 8916\n",
    "\n",
    "images = sorted(os.listdir(TRAIN_IMAGE_DIR))\n",
    "labels = sorted(os.listdir(TRAIN_LABELS_DIR))\n",
    "print(len(images))\n",
    "\n",
    "# count = 0\n",
    "for i in range(len(images)):\n",
    "    print(labels[i])\n",
    "    image = load_img(TRAIN_IMAGE_DIR+'/'+images[i])\n",
    "    \n",
    "    label = np.load(TRAIN_LABELS_DIR+'/'+labels[i])\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.savefig('/home/naproxa/cs271proj/image1.png')\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.imshow(label, alpha=0.3)\n",
    "    \n",
    "    plt.figure()\n",
    " \n",
    "    plt.imshow(label)\n",
    "    plt.savefig('/home/jjonathanmak/cs271proj/label1.png')\n",
    "    break\n",
    "#     count += 1\n",
    "#     if count == 3: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(IMAGE_DIR, LABEL_DIR):\n",
    "\n",
    "    images = []\n",
    "    image_list = sorted(os.listdir(IMAGE_DIR))\n",
    "    if LABEL_DIR:\n",
    "        labels = []\n",
    "        label_list = sorted(os.listdir(LABEL_DIR))\n",
    "\n",
    "    for file in tqdm(range(len(image_list))):\n",
    "\n",
    "        image_path = IMAGE_DIR +'/'+image_list[i]\n",
    "        \n",
    "        # image is duplicated across channels, take 1st channel\n",
    "        img = img_to_array(load_img(image_path), dtype=np.uint8)\n",
    "         \n",
    "        images.append(img[:, :, 0])\n",
    "        \n",
    "        if LABEL_DIR:\n",
    "            label_path = LABEL_DIR +'/'+label_list[i]\n",
    "            label = np.load(label_path)\n",
    "            labels.append(label)\n",
    "\n",
    "    if LABEL_DIR:\n",
    "        return np.array(images), np.array(labels)\n",
    "    else:\n",
    "        return np.array(images)\n",
    "\n",
    "train_images, train_labels = load_data(TRAIN_IMAGE_DIR, TRAIN_LABELS_DIR)\n",
    "val_images, val_labels = load_data(VAL_IMAGE_DIR, VAL_LABELS_DIR)\n",
    "test_images = load_data(TEST_IMAGE_DIR, None)\n",
    "\n",
    "print('Train images: ', train_images.shape)\n",
    "print('Train labels: ', train_labels.shape)\n",
    "print('Val images: ', val_images.shape)\n",
    "print('Val labels: ', val_labels.shape)\n",
    "print('Test images: ', test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).batch(BATCH_SIZE)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: logs/eye_segmentation20200301T0440/mask_rcnn_eye_segmentation_{epoch:04d}.h5\n",
      "In model:  rpn_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjonathanmak/miniconda3/envs/biods220-env/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/jjonathanmak/miniconda3/envs/biods220-env/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/jjonathanmak/miniconda3/envs/biods220-env/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... can't pickle _thread.RLock objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error processing image {'id': '000000292567', 'source': 'eye', 'path': '/home/jjonathanmak/cs271proj/Semantic_Segmentation_Dataset/validation/images/000000292567.png'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1704, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1206, in load_image_gt\n",
      "    image = dataset.load_eyes(image_id)\n",
      "  File \"/home/jjonathanmak/cs271proj/eye_segmentation.py\", line 133, in load_eyes\n",
      "    if \"images\" in dataset_dir:\n",
      "TypeError: argument of type 'numpy.int64' is not iterable\n",
      "ERROR:root:Error processing image {'id': '000000262478', 'source': 'eye', 'path': '/home/jjonathanmak/cs271proj/Semantic_Segmentation_Dataset/validation/images/000000262478.png'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1704, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1206, in load_image_gt\n",
      "    image = dataset.load_eyes(image_id)\n",
      "  File \"/home/jjonathanmak/cs271proj/eye_segmentation.py\", line 133, in load_eyes\n",
      "    if \"images\" in dataset_dir:\n",
      "TypeError: argument of type 'numpy.int64' is not iterable\n",
      "ERROR:root:Error processing image {'id': '000000232438', 'source': 'eye', 'path': '/home/jjonathanmak/cs271proj/Semantic_Segmentation_Dataset/train/images/000000232438.png'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1704, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1206, in load_image_gt\n",
      "    image = dataset.load_eyes(image_id)\n",
      "  File \"/home/jjonathanmak/cs271proj/eye_segmentation.py\", line 133, in load_eyes\n",
      "    if \"images\" in dataset_dir:\n",
      "TypeError: argument of type 'numpy.int64' is not iterable\n",
      "ERROR:root:Error processing image {'id': '000000311797', 'source': 'eye', 'path': '/home/jjonathanmak/cs271proj/Semantic_Segmentation_Dataset/validation/images/000000311797.png'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1704, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1206, in load_image_gt\n",
      "    image = dataset.load_eyes(image_id)\n",
      "  File \"/home/jjonathanmak/cs271proj/eye_segmentation.py\", line 133, in load_eyes\n",
      "    if \"images\" in dataset_dir:\n",
      "TypeError: argument of type 'numpy.int64' is not iterable\n",
      "ERROR:root:Error processing image {'id': '000000240706', 'source': 'eye', 'path': '/home/jjonathanmak/cs271proj/Semantic_Segmentation_Dataset/train/images/000000240706.png'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1704, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1206, in load_image_gt\n",
      "    image = dataset.load_eyes(image_id)\n",
      "  File \"/home/jjonathanmak/cs271proj/eye_segmentation.py\", line 133, in load_eyes\n",
      "    if \"images\" in dataset_dir:\n",
      "TypeError: argument of type 'numpy.int64' is not iterable\n",
      "ERROR:root:Error processing image {'id': '000000303596', 'source': 'eye', 'path': '/home/jjonathanmak/cs271proj/Semantic_Segmentation_Dataset/validation/images/000000303596.png'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1704, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1206, in load_image_gt\n",
      "    image = dataset.load_eyes(image_id)\n",
      "  File \"/home/jjonathanmak/cs271proj/eye_segmentation.py\", line 133, in load_eyes\n",
      "    if \"images\" in dataset_dir:\n",
      "TypeError: argument of type 'numpy.int64' is not iterable\n",
      "ERROR:root:Error processing image {'id': '000000063015', 'source': 'eye', 'path': '/home/jjonathanmak/cs271proj/Semantic_Segmentation_Dataset/train/images/000000063015.png'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1704, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1206, in load_image_gt\n",
      "    image = dataset.load_eyes(image_id)\n",
      "  File \"/home/jjonathanmak/cs271proj/eye_segmentation.py\", line 133, in load_eyes\n",
      "    if \"images\" in dataset_dir:\n",
      "TypeError: argument of type 'numpy.int64' is not iterable\n",
      "ERROR:root:Error processing image {'id': '000000303573', 'source': 'eye', 'path': '/home/jjonathanmak/cs271proj/Semantic_Segmentation_Dataset/validation/images/000000303573.png'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1704, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1206, in load_image_gt\n",
      "    image = dataset.load_eyes(image_id)\n",
      "  File \"/home/jjonathanmak/cs271proj/eye_segmentation.py\", line 133, in load_eyes\n",
      "    if \"images\" in dataset_dir:\n",
      "TypeError: argument of type 'numpy.int64' is not iterable\n",
      "ERROR:root:Error processing image {'id': '000000161582', 'source': 'eye', 'path': '/home/jjonathanmak/cs271proj/Semantic_Segmentation_Dataset/train/images/000000161582.png'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1704, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1206, in load_image_gt\n",
      "    image = dataset.load_eyes(image_id)\n",
      "  File \"/home/jjonathanmak/cs271proj/eye_segmentation.py\", line 133, in load_eyes\n",
      "    if \"images\" in dataset_dir:\n",
      "TypeError: argument of type 'numpy.int64' is not iterable\n",
      "ERROR:root:Error processing image {'id': '000000311771', 'source': 'eye', 'path': '/home/jjonathanmak/cs271proj/Semantic_Segmentation_Dataset/validation/images/000000311771.png'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1704, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1206, in load_image_gt\n",
      "    image = dataset.load_eyes(image_id)\n",
      "  File \"/home/jjonathanmak/cs271proj/eye_segmentation.py\", line 133, in load_eyes\n",
      "    if \"images\" in dataset_dir:\n",
      "TypeError: argument of type 'numpy.int64' is not iterable\n",
      "ERROR:root:Error processing image {'id': '000000079566', 'source': 'eye', 'path': '/home/jjonathanmak/cs271proj/Semantic_Segmentation_Dataset/train/images/000000079566.png'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1704, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1206, in load_image_gt\n",
      "    image = dataset.load_eyes(image_id)\n",
      "  File \"/home/jjonathanmak/cs271proj/eye_segmentation.py\", line 133, in load_eyes\n",
      "    if \"images\" in dataset_dir:\n",
      "TypeError: argument of type 'numpy.int64' is not iterable\n",
      "ERROR:root:Error processing image {'id': '000000087702', 'source': 'eye', 'path': '/home/jjonathanmak/cs271proj/Semantic_Segmentation_Dataset/train/images/000000087702.png'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1704, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/home/jjonathanmak/cs271proj/mask_rcnn.py\", line 1206, in load_image_gt\n",
      "    image = dataset.load_eyes(image_id)\n",
      "  File \"/home/jjonathanmak/cs271proj/eye_segmentation.py\", line 133, in load_eyes\n",
      "    if \"images\" in dataset_dir:\n",
      "TypeError: argument of type 'numpy.int64' is not iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2150\n",
      "741\n",
      "6020\n",
      "336\n",
      "8783\n",
      "1306\n",
      "8482\n",
      "761\n",
      "1079\n",
      "2357\n",
      "2325\n",
      "1888\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'numpy.int64' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-703e39a708bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meye_segmentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mrcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/cs271proj/eye_segmentation.py\u001b[0m in \u001b[0;36mtrain_mrcnn\u001b[0;34m(load_last)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# Inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs271proj/eye_segmentation.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                 \u001b[0maugmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maugmentation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                 layers='heads')\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train all layers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs271proj/mask_rcnn.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[1;32m   2365\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2366\u001b[0m             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVALIDATION_STEPS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2367\u001b[0;31m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2368\u001b[0m \u001b[0;31m#             workers=workers,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2369\u001b[0m \u001b[0;31m#             use_multiprocessing=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/biods220-env/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/biods220-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/biods220-env/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/biods220-env/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    740\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[0;32m--> 742\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/biods220-env/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/biods220-env/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/biods220-env/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/biods220-env/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/biods220-env/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[0;34m(uid)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \"\"\"\n\u001b[0;32m--> 650\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs271proj/mask_rcnn.py\u001b[0m in \u001b[0;36mdata_generator\u001b[0;34m(dataset, config, shuffle, augment, augmentation, random_rois, batch_size, detection_targets, no_augmentation_sources)\u001b[0m\n\u001b[1;32m   1702\u001b[0m                     load_image_gt(dataset, config, image_id, augment=augment,\n\u001b[1;32m   1703\u001b[0m                                 \u001b[0maugmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maugmentation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1704\u001b[0;31m                                 use_mini_mask=config.USE_MINI_MASK)\n\u001b[0m\u001b[1;32m   1705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m             \u001b[0;31m# Skip images that have no instances. This can happen in cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs271proj/mask_rcnn.py\u001b[0m in \u001b[0;36mload_image_gt\u001b[0;34m(dataset, config, image_id, augment, augmentation, use_mini_mask)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[0;31m# Load image and mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_eyes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m     \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m     \u001b[0moriginal_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs271proj/eye_segmentation.py\u001b[0m in \u001b[0;36mload_eyes\u001b[0;34m(self, dataset_dir)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m# if dataset_dir not null:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"images\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0mimage_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'numpy.int64' is not iterable"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model = eye_segmentation.train_mrcnn(load_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
